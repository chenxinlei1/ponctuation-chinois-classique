{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f74ba9",
   "metadata": {},
   "source": [
    "### Traitement du corpus\n",
    "- Filtrer les textes qui contiennent une ponctuation (parce que certains textes n'ont pas de ponctuation)\n",
    "- supprimer les textes répétés\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb52dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers avec ponctuation (après déduplication) : 64\n",
      "Nombre de fichiers sans ponctuation (après déduplication) : 13\n",
      "Tous les fichiers avec ponctuation ont été enregistrés dans le répertoire : Corpus/十國春秋(avec ponctuation)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import shutil\n",
    "\n",
    "# Définir le chemin du répertoire de texte\n",
    "text_dir = \"Corpus/十國春秋\"\n",
    "output_dir = \"Corpus/十國春秋(avec ponctuation)\"  # Répertoire de sortie (modifiable)\n",
    "\n",
    "# Créer le répertoire de sortie s'il n'existe pas\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Expression régulière pour la ponctuation chinoise\n",
    "punctuation_pattern = re.compile(r\"[。！？]\")\n",
    "\n",
    "punctuated_files = []\n",
    "unpunctuated_files = []\n",
    "seen_hashes = set()\n",
    "\n",
    "# Parcourir les fichiers dans le répertoire\n",
    "for file in os.listdir(text_dir):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(text_dir, file)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read().strip()\n",
    "                content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()\n",
    "                if content_hash in seen_hashes:\n",
    "                    continue\n",
    "                seen_hashes.add(content_hash)\n",
    "\n",
    "                if punctuation_pattern.search(content):\n",
    "                    punctuated_files.append(file_path)\n",
    "                    # Copier le fichier dans le répertoire de sortie\n",
    "                    shutil.copy(file_path, os.path.join(output_dir, file))\n",
    "                else:\n",
    "                    unpunctuated_files.append(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Échec de la lecture : {file} → {e}\")\n",
    "\n",
    "print(f\"Nombre de fichiers avec ponctuation (après déduplication) : {len(punctuated_files)}\")\n",
    "print(f\"Nombre de fichiers sans ponctuation (après déduplication) : {len(unpunctuated_files)}\")\n",
    "print(f\"Tous les fichiers avec ponctuation ont été enregistrés dans le répertoire : {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba19d0",
   "metadata": {},
   "source": [
    "### Nettoyage des textes sélectionnés\n",
    "supprimer les hyperliens, lignes non pertinentes, annotations décoratives, chiffres, caractères spéciaux, espaces et sauts de ligne inappropriés, afin d'améliorer la clarté et la cohérence du contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e7828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nettoyé : 卷二十一.txt\n",
      "Nettoyé : 卷三十七.txt\n",
      "Nettoyé : 卷068.txt\n",
      "Nettoyé : 卷七.txt\n",
      "Nettoyé : 卷069.txt\n",
      "Nettoyé : 卷十二.txt\n",
      "Nettoyé : 卷094.txt\n",
      "Nettoyé : 卷一.txt\n",
      "Nettoyé : 卷十八.txt\n",
      "Nettoyé : 卷二十.txt\n",
      "Nettoyé : 卷084.txt\n",
      "Nettoyé : 卷086.txt\n",
      "Nettoyé : 卷十六.txt\n",
      "Nettoyé : 卷十七.txt\n",
      "Nettoyé : 卷023.txt\n",
      "Nettoyé : 卷二.txt\n",
      "Nettoyé : 卷022.txt\n",
      "Nettoyé : 卷036.txt\n",
      "Nettoyé : 凡例.txt\n",
      "Nettoyé : 卷二十八.txt\n",
      "Nettoyé : 卷十一.txt\n",
      "Nettoyé : 卷008.txt\n",
      "Nettoyé : 卷009.txt\n",
      "Nettoyé : 卷035.txt\n",
      "Nettoyé : 卷019.txt\n",
      "Nettoyé : 卷025.txt\n",
      "Nettoyé : 卷030.txt\n",
      "Nettoyé : 卷024.txt\n",
      "Nettoyé : 卷026.txt\n",
      "Nettoyé : 卷六.txt\n",
      "Nettoyé : 卷027.txt\n",
      "Nettoyé : 卷003.txt\n",
      "Nettoyé : 卷十三.txt\n",
      "Nettoyé : 卷十四.txt\n",
      "Nettoyé : 卷015.txt\n",
      "Nettoyé : 卷029.txt\n",
      "Nettoyé : 跋.txt\n",
      "Nettoyé : 卷004.txt\n",
      "Nettoyé : 卷010.txt\n",
      "Nettoyé : 提要.txt\n",
      "Nettoyé : 卷五.txt\n",
      "Nettoyé : 自序.txt\n",
      "Nettoyé : 卷075.txt\n",
      "Nettoyé : 卷061.txt\n",
      "Nettoyé : 卷101.txt\n",
      "Nettoyé : 卷100.txt\n",
      "Nettoyé : 卷060.txt\n",
      "Nettoyé : 卷074.txt\n",
      "Nettoyé : 卷062.txt\n",
      "Nettoyé : 卷076.txt\n",
      "Nettoyé : 卷102.txt\n",
      "Nettoyé : 卷103.txt\n",
      "Nettoyé : 卷077.txt\n",
      "Nettoyé : 卷067.txt\n",
      "Nettoyé : 卷073.txt\n",
      "Nettoyé : 卷113.txt\n",
      "Nettoyé : 卷072.txt\n",
      "Nettoyé : 卷058.txt\n",
      "Nettoyé : 卷070.txt\n",
      "Nettoyé : 卷104.txt\n",
      "Nettoyé : 卷111.txt\n",
      "Nettoyé : 卷105.txt\n",
      "Nettoyé : 卷071.txt\n",
      "Nettoyé : 卷059.txt\n",
      "Tous les fichiers ont été nettoyés et enregistrés dans : Corpus/十國春秋_cleaned\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Supprimer les hyperliens\n",
    "    text = re.sub(r\"http[s]?://\\S+\", \"\", text)\n",
    "\n",
    "    # Supprimer les lignes non pertinentes spécifiques\n",
    "    text = re.sub(r\"^.*(←|→|目次|姊妹計劃|作者).*?$\", \"\", text, flags=re.M)\n",
    "\n",
    "    # Supprimer les annotations ou les marques décoratives\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "    text = re.sub(r\"【.*?】\", \"\", text)\n",
    "\n",
    "    # Supprimer les chiffres\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # Supprimer les caractères de contrôle spéciaux\n",
    "    text = re.sub(r\"[\\u2000-\\u206F\\uFEFF\\uFFF0-\\uFFFF]\", \"\", text)\n",
    "    text = re.sub(r\"[𦞦𤴓䤬䍧𢂽□*]\", \"\", text)\n",
    "\n",
    "    # Supprimer les sauts de ligne entre deux caractères non blancs\n",
    "    text = re.sub(r\"(?<=[\\S])\\n(?=[\\S])\", \"\", text)\n",
    "\n",
    "    # Supprimer les espaces demi-chasse et pleine chasse\n",
    "    text = text.replace(\" \", \"\").replace(\"　\", \"\")\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "# Définir les chemins d’entrée et de sortie\n",
    "input_dir = \"Corpus/十國春秋(avec ponctuation)\"\n",
    "output_dir = \"Corpus/十國春秋_cleaned\"  # Répertoire des textes nettoyés\n",
    "\n",
    "# Créer le répertoire de sortie s’il n’existe pas\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Parcourir et nettoyer chaque fichier texte\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        input_path = os.path.join(input_dir, file_name)\n",
    "        output_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "        try:\n",
    "            with open(input_path, 'r', encoding='utf-8') as f:\n",
    "                raw_text = f.read()\n",
    "                cleaned_text = clean_text(raw_text)\n",
    "\n",
    "            with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "                f_out.write(cleaned_text)\n",
    "\n",
    "            print(f\"Nettoyé : {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Échec du traitement : {file_name} → {e}\")\n",
    "\n",
    "print(f\"Tous les fichiers ont été nettoyés et enregistrés dans : {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ancient-punc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
